# to-read-list


- https://arxiv.org/abs/2112.01898
- https://f-charton.github.io/polynomial-roots/
- https://yj-yu.github.io/home/data/esper.pdf
- https://arxiv.org/pdf/2205.13636.pdf
- https://github.com/KaliYuga-ai/Pixel-Art-Diffusion/blob/e037fd58e2aef58f28d7511ea6dcb184e898e39f/Pixel_Art_Diffusion_v1_0.ipynb
- https://github.com/FreddeFrallan/Multilingual-CLIP#inference-usage
- https://arxiv.org/abs/2205.15834
- https://arxiv.org/abs/2110.11309
- https://arxiv.org/pdf/2204.03044.pdf
- https://arxiv.org/abs/2111.09839
- https://arxiv.org/abs/2111.09832
- https://github.com/imfing/ava_downloader
- https://arxiv.org/abs/2205.11508
- https://arxiv.org/abs/2205.11502
- https://aclanthology.org/2022.bigscience-1.3/
- https://arxiv.org/abs/2201.02177
- https://arxiv.org/abs/2205.09273
- https://arxiv.org/abs/2109.07460
- https://huggingface.co/minimaxir/ai-generated-pokemon-rudalle
- https://arxiv.org/abs/2204.10019
- https://arxiv.org/abs/2205.14217
- https://arxiv.org/abs/2206.01861
- https://github.com/openai/guided-diffusion
- https://arxiv.org/abs/2106.01345
- https://github.com/XiangLi1999/Diffusion-LM
- https://multimodal.art/news/this-week-in-multimodal-ai-art-31-may-06-jun
- https://arxiv.org/pdf/2205.14459.pdf
- https://github.com/lvwerra/trl


6/22/22:
- https://arxiv.org/abs/2107.07075
- https://github.com/pesser/stable-diffusion
- https://arxiv.org/pdf/2206.07137.pdf (https://github.com/OATML/RHO-Loss)
- http://www.lrec-conf.org/proceedings/lrec2022/pdf/2022.lrec-1.376.pdf
- ExT5 https://arxiv.org/pdf/2111.10952.pdf
- Towards Understanding Grokking https://arxiv.org/abs/2205.10343
- Emergent Abilities https://arxiv.org/pdf/2206.07682.pdf
- DIRECTOR: Generator-CLassifiers https://arxiv.org/abs/2206.07694
- Decentralized Training https://arxiv.org/pdf/2206.01288.pdf
- t-few codebase https://github.com/r-three/t-few
- https://arxiv.org/abs/2202.07765 https://github.com/google-research/perceiver-ar/blob/main/perceiver_ar/perceiver_ar_model.py
- t5x ckpts https://github.com/google-research/t5x/blob/main/docs/models.md#converted-mesh-tensorflow-checkpoints
- Neural Basis Models for Interpretability https://arxiv.org/abs/2205.14120
- Scalable Interpretability by Polynomials https://arxiv.org/abs/2205.14108
- UniLM https://arxiv.org/pdf/1905.03197.pdf
- CM3 https://arxiv.org/pdf/2201.07520.pdf
- Jax Monte Carlo Tree Search: https://github.com/deepmind/mctx
- Differentiable Finite State Machines https://google-research.github.io/self-organising-systems/2022/diff-fsm/
- Multigame DTs https://arxiv.org/abs/2205.15241
- Shampoo in PyTorch https://github.com/facebookresearch/optimizers/tree/main/shampoo
- Ghost in the Machine https://arxiv.org/ftp/arxiv/papers/2203/2203.07785.pdf
- https://github.com/stancld/longt5-eval



7/13/22
- Structured Pruning Learns Compact and Accurate Models https://arxiv.org/pdf/2204.00408.pdf
- Making Pre-trained Language Models Better Few-Shot Learners https://aclanthology.org/2021.acl-long.295.pdf
- Training Language Models With Memory Augmentation https://arxiv.org/pdf/2205.12674.pdf
- On the Paradox of Learning To Reason From Data https://arxiv.org/abs/2205.11502
- Should You Mask 15% in Masked Language Modeling? https://arxiv.org/pdf/2202.08005.pdf
- Annotated S4 https://github.com/srush/annotated-s4
- Recovering Private Text in Federated Learning of Language Models https://arxiv.org/pdf/2205.08514.pdf
- Named Tensor Notation https://arxiv.org/pdf/2102.13196.pdf
- How Many Data Points is A Prompt Worth? https://arxiv.org/pdf/2103.08493.pdf
- Block Pruning For Faster Transformers https://arxiv.org/pdf/2109.04838.pdf
- In-Context Tuning https://github.com/yandachen/In-context-Tuning https://arxiv.org/pdf/2110.07814.pdf
- Exploring the Role of Task Transferability in Multi-Task Training https://arxiv.org/pdf/2204.11117.pdf
- Maieutic Prompting: Logically Consistent Reasoning With Recursive Explanations https://arxiv.org/abs/2205.11822
- Language Models in the Loop: Incorporating Prompting into Weak Supervision https://arxiv.org/pdf/2205.02318.pdf
- QA Infused Pretraining of General-purpose Contextualized Representations https://arxiv.org/pdf/2106.08190.pdf
- Can Small and Synthetic Benchmarks Drive Innovation? https://arxiv.org/pdf/2102.01065.pdf






